{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89076f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T18:36:22.111915Z",
     "iopub.status.busy": "2024-09-10T18:36:22.111585Z",
     "iopub.status.idle": "2024-09-10T18:36:26.661575Z",
     "shell.execute_reply": "2024-09-10T18:36:26.660757Z"
    },
    "papermill": {
     "duration": 4.557394,
     "end_time": "2024-09-10T18:36:26.663934",
     "exception": false,
     "start_time": "2024-09-10T18:36:22.106540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: sentencepiece\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed sentencepiece-0.2.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16078a9",
   "metadata": {
    "_cell_guid": "c4ad26dd-8d2a-43e9-a3ea-0a4342a16e52",
    "_uuid": "07d7bc95-0377-4db3-aa05-2bd6cf989e78",
    "execution": {
     "iopub.execute_input": "2024-09-10T18:36:26.673943Z",
     "iopub.status.busy": "2024-09-10T18:36:26.673683Z",
     "iopub.status.idle": "2024-09-10T18:36:59.686883Z",
     "shell.execute_reply": "2024-09-10T18:36:59.686035Z"
    },
    "papermill": {
     "duration": 33.020792,
     "end_time": "2024-09-10T18:36:59.689303",
     "exception": false,
     "start_time": "2024-09-10T18:36:26.668511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1725993393.264808      77 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: ===\n",
      "learning/45eac/tfrc/runtime/common_lib.cc:479\n",
      "D0910 18:36:33.272946284      77 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\n",
      "D0910 18:36:33.272961149      77 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\n",
      "D0910 18:36:33.272964286      77 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\n",
      "D0910 18:36:33.272966677      77 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\n",
      "D0910 18:36:33.272969145      77 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\n",
      "D0910 18:36:33.272971491      77 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\n",
      "D0910 18:36:33.272973748      77 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\n",
      "D0910 18:36:33.272976099      77 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\n",
      "D0910 18:36:33.272978232      77 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\n",
      "D0910 18:36:33.272980356      77 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\n",
      "D0910 18:36:33.272982633      77 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\n",
      "D0910 18:36:33.272984807      77 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\n",
      "D0910 18:36:33.272986921      77 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\n",
      "D0910 18:36:33.272989042      77 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\n",
      "D0910 18:36:33.272991166      77 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\n",
      "D0910 18:36:33.272993311      77 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\n",
      "D0910 18:36:33.272995576      77 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\n",
      "D0910 18:36:33.272997772      77 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\n",
      "D0910 18:36:33.272999946      77 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\n",
      "D0910 18:36:33.273002123      77 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\n",
      "D0910 18:36:33.273004263      77 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\n",
      "D0910 18:36:33.273006433      77 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\n",
      "D0910 18:36:33.273008663      77 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\n",
      "D0910 18:36:33.273010818      77 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\n",
      "D0910 18:36:33.273012911      77 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\n",
      "D0910 18:36:33.273015009      77 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\n",
      "D0910 18:36:33.273017207      77 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\n",
      "D0910 18:36:33.273019396      77 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\n",
      "D0910 18:36:33.273021687      77 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\n",
      "D0910 18:36:33.273024941      77 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\n",
      "D0910 18:36:33.273027189      77 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\n",
      "D0910 18:36:33.273029401      77 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\n",
      "D0910 18:36:33.273031752      77 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\n",
      "D0910 18:36:33.273033932      77 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\n",
      "D0910 18:36:33.273036057      77 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\n",
      "D0910 18:36:33.273038214      77 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\n",
      "D0910 18:36:33.273040326      77 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\n",
      "D0910 18:36:33.273042438      77 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\n",
      "D0910 18:36:33.273044646      77 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\n",
      "D0910 18:36:33.273046825      77 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\n",
      "D0910 18:36:33.273048949      77 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\n",
      "D0910 18:36:33.273051063      77 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\n",
      "D0910 18:36:33.273053216      77 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\n",
      "D0910 18:36:33.273055456      77 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\n",
      "D0910 18:36:33.273057659      77 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\n",
      "I0910 18:36:33.273263825      77 ev_epoll1_linux.cc:123]               grpc epoll fd: 57\n",
      "D0910 18:36:33.273277847      77 ev_posix.cc:113]                      Using polling engine: epoll1\n",
      "D0910 18:36:33.285780615      77 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\n",
      "D0910 18:36:33.285792953      77 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\n",
      "D0910 18:36:33.285801091      77 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\n",
      "D0910 18:36:33.285804182      77 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\n",
      "D0910 18:36:33.285807171      77 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\n",
      "D0910 18:36:33.285809886      77 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\n",
      "D0910 18:36:33.285839383      77 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\n",
      "D0910 18:36:33.285850560      77 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\n",
      "D0910 18:36:33.285872790      77 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\n",
      "D0910 18:36:33.285893598      77 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\n",
      "D0910 18:36:33.285900898      77 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D0910 18:36:33.285903894      77 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\n",
      "D0910 18:36:33.285907906      77 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\n",
      "D0910 18:36:33.285910865      77 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\n",
      "D0910 18:36:33.285914005      77 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\n",
      "D0910 18:36:33.285917535      77 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\n",
      "D0910 18:36:33.285946219      77 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\n",
      "I0910 18:36:33.287801587      77 ev_epoll1_linux.cc:359]               grpc epoll fd: 59\n",
      "I0910 18:36:33.288954550      77 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0910 18:36:33.292216130     183 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0910 18:36:33.292269103     183 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\n",
      "E0910 18:36:33.298684249     173 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2024-09-10T18:36:33.298669475+00:00\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 8 # per TPU core\n",
    "TOTAL_STEPS = 2000  # thats approx 4 epochs\n",
    "EVALUATE_EVERY = 200\n",
    "LR =  1e-5\n",
    "\n",
    "PRETRAINED_MODEL = 'jplu/tf-xlm-roberta-large'\n",
    "D = '/kaggle/input/jigsaw-multilingual-toxic-comment-classification/'\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import transformers\n",
    "from transformers import TFAutoModelWithLMHead, AutoTokenizer\n",
    "import logging\n",
    "# no extensive logging \n",
    "logging.getLogger().setLevel(logging.NOTSET)\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ccd56c3",
   "metadata": {
    "_cell_guid": "86a303dd-5d1d-4d3f-bf28-4a02b6816e9b",
    "_uuid": "5a5fd45e-8f97-44d8-95f6-29cc8563dc3d",
    "execution": {
     "iopub.execute_input": "2024-09-10T18:36:59.708221Z",
     "iopub.status.busy": "2024-09-10T18:36:59.707781Z",
     "iopub.status.idle": "2024-09-10T18:37:09.149425Z",
     "shell.execute_reply": "2024-09-10T18:37:09.148533Z"
    },
    "papermill": {
     "duration": 9.451823,
     "end_time": "2024-09-10T18:37:09.154298",
     "exception": false,
     "start_time": "2024-09-10T18:36:59.702475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  \n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725993424.212617      77 service.cc:145] XLA service 0x563c462aa130 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1725993424.212667      77 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\n",
      "I0000 00:00:1725993424.212671      77 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\n",
      "I0000 00:00:1725993424.212674      77 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\n",
      "I0000 00:00:1725993424.212677      77 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\n",
      "I0000 00:00:1725993424.212679      77 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\n",
      "I0000 00:00:1725993424.212682      77 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\n",
      "I0000 00:00:1725993424.212684      77 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\n",
      "I0000 00:00:1725993424.212688      77 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use the non-experimental symbol `tf.distribute.TPUStrategy` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "def connect_to_TPU():\n",
    "    \"\"\"Detect hardware, return appropriate distribution strategy\"\"\"\n",
    "    try:\n",
    "        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "        # set: this is always the case on Kaggle.\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    else:\n",
    "        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "\n",
    "    global_batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "    return tpu, strategy, global_batch_size\n",
    "\n",
    "\n",
    "tpu, strategy, global_batch_size = connect_to_TPU()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc8dc0a",
   "metadata": {
    "_cell_guid": "1cba2ff3-145e-4187-a6a4-60d28adf5141",
    "_uuid": "80b620f4-85cd-4436-b868-acdcea7bf2b6",
    "execution": {
     "iopub.execute_input": "2024-09-10T18:37:09.179838Z",
     "iopub.status.busy": "2024-09-10T18:37:09.179523Z",
     "iopub.status.idle": "2024-09-10T18:37:27.915254Z",
     "shell.execute_reply": "2024-09-10T18:37:27.914351Z"
    },
    "papermill": {
     "duration": 18.745659,
     "end_time": "2024-09-10T18:37:27.918197",
     "exception": false,
     "start_time": "2024-09-10T18:37:09.172538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "D_TRANS = '/kaggle/input/jigsaw-train-multilingual-coments-google-api/'\n",
    "\n",
    "def load_jigsaw_trans(langs=['tr','it','es','ru','fr','pt'], \n",
    "                      columns=['comment_text', 'toxic']):\n",
    "    train_6langs=[]\n",
    "    for i in range(len(langs)):\n",
    "        fn = D_TRANS+'jigsaw-toxic-comment-train-google-%s-cleaned.csv'%langs[i]\n",
    "        train_6langs.append(downsample(pd.read_csv(fn)[columns]))\n",
    "\n",
    "    return train_6langs\n",
    "\n",
    "def downsample(df):\n",
    "    \"\"\"Subsample the train dataframe to 50%-50%\"\"\"\n",
    "    ds_df= pd.concat([\n",
    "        df.query('toxic==1'),\n",
    "        df.query('toxic==0').sample(sum(df.toxic))\n",
    "    ])\n",
    "    \n",
    "    return ds_df\n",
    "    \n",
    "\n",
    "train_df = pd.concat(load_jigsaw_trans()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4f38ab",
   "metadata": {
    "_cell_guid": "900f2d01-b87c-42e7-8cc2-8dcba95ffa54",
    "_uuid": "7d5605a3-df77-4574-9899-89529d0a6e61",
    "execution": {
     "iopub.execute_input": "2024-09-10T18:37:27.951959Z",
     "iopub.status.busy": "2024-09-10T18:37:27.951631Z",
     "iopub.status.idle": "2024-09-10T18:37:59.734392Z",
     "shell.execute_reply": "2024-09-10T18:37:59.733255Z"
    },
    "papermill": {
     "duration": 31.806897,
     "end_time": "2024-09-10T18:37:59.750225",
     "exception": false,
     "start_time": "2024-09-10T18:37:27.943328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/tokenizer_config.json HTTP/11\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/config.json HTTP/11\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to acquire lock 134132173918640 on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/3acc6bc7228b5c03c361e36291bc513a51090e40.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Lock 134132173918640 acquired on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/3acc6bc7228b5c03c361e36291bc513a51090e40.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /jplu/tf-xlm-roberta-large/resolve/main/config.json HTTP/11\" 200 513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 134132173918640 on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/3acc6bc7228b5c03c361e36291bc513a51090e40.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Lock 134132173918640 released on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/3acc6bc7228b5c03c361e36291bc513a51090e40.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/tokenizer_config.json HTTP/11\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/sentencepiece.bpe.model HTTP/11\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to acquire lock 134099422201792 on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/db9af13bf09fd3028ca32be90d3fb66d5e470399.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Lock 134099422201792 acquired on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/db9af13bf09fd3028ca32be90d3fb66d5e470399.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /jplu/tf-xlm-roberta-large/resolve/main/sentencepiece.bpe.model HTTP/11\" 200 5069051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 134099422201792 on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/db9af13bf09fd3028ca32be90d3fb66d5e470399.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Lock 134099422201792 released on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/db9af13bf09fd3028ca32be90d3fb66d5e470399.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/tokenizer.json HTTP/11\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/added_tokens.json HTTP/11\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/special_tokens_map.json HTTP/11\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 50s, sys: 37 s, total: 13min 27s\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def regular_encode(texts, tokenizer, maxlen=512):\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts.tolist(),  # Convert NumPy array to list\n",
    "        return_attention_mask=False,  \n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    \n",
    "    return np.array(enc_di['input_ids'])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "X_train = regular_encode(train_df.comment_text.values, tokenizer, maxlen=MAX_LEN)\n",
    "# X_val = regular_encode(val_df.comment_text.values, tokenizer, maxlen=MAX_LEN)\n",
    "# X_test = regular_encode(test_df.content.values, tokenizer, maxlen=MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c0a48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T18:37:59.782068Z",
     "iopub.status.busy": "2024-09-10T18:37:59.781728Z",
     "iopub.status.idle": "2024-09-10T18:38:01.177159Z",
     "shell.execute_reply": "2024-09-10T18:38:01.176065Z"
    },
    "papermill": {
     "duration": 1.407416,
     "end_time": "2024-09-10T18:38:01.179708",
     "exception": false,
     "start_time": "2024-09-10T18:37:59.772292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_mlm_input_and_labels(X):\n",
    "    # 15% BERT masking\n",
    "    inp_mask = np.random.rand(*X.shape)<0.15 \n",
    "    # do not mask special tokens\n",
    "    inp_mask[X<=2] = False\n",
    "    # set targets to -1 by default, it means ignore\n",
    "    labels =  -1 * np.ones(X.shape, dtype=int)\n",
    "    # set labels for masked tokens\n",
    "    labels[inp_mask] = X[inp_mask]\n",
    "    \n",
    "    # prepare input\n",
    "    X_mlm = np.copy(X)\n",
    "    # set input to [MASK] which is the last token for the 90% of tokens\n",
    "    # this means leaving 10% unchanged\n",
    "    inp_mask_2mask = inp_mask  & (np.random.rand(*X.shape)<0.90)\n",
    "    X_mlm[inp_mask_2mask] = 250001  # mask token is the last in the dict\n",
    "\n",
    "    # set 10% to a random token\n",
    "    inp_mask_2random = inp_mask_2mask  & (np.random.rand(*X.shape) < 1/9)\n",
    "    X_mlm[inp_mask_2random] = np.random.randint(3, 250001, inp_mask_2random.sum())\n",
    "    \n",
    "    return X_mlm, labels\n",
    "\n",
    "\n",
    "\n",
    "X_train_mlm, y_train_mlm = prepare_mlm_input_and_labels(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3268eb0",
   "metadata": {
    "_cell_guid": "757b2c93-9c07-441d-ba2e-47b8607b3795",
    "_uuid": "8b748024-314d-4256-b67b-0bc71ecac19d",
    "execution": {
     "iopub.execute_input": "2024-09-10T18:38:01.209882Z",
     "iopub.status.busy": "2024-09-10T18:38:01.209575Z",
     "iopub.status.idle": "2024-09-10T18:38:02.376505Z",
     "shell.execute_reply": "2024-09-10T18:38:02.375355Z"
    },
    "papermill": {
     "duration": 1.17779,
     "end_time": "2024-09-10T18:38:02.378939",
     "exception": false,
     "start_time": "2024-09-10T18:38:01.201149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dist_dataset(X, y=None, training=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "\n",
    "    ### Add y if present ###\n",
    "    if y is not None:\n",
    "        dataset_y = tf.data.Dataset.from_tensor_slices(y)\n",
    "        dataset = tf.data.Dataset.zip((dataset, dataset_y))\n",
    "        \n",
    "    ### Repeat if training ###\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(len(X)).repeat()\n",
    "\n",
    "    dataset = dataset.batch(global_batch_size).prefetch(AUTO)\n",
    "\n",
    "    ### make it distributed  ###\n",
    "    dist_dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "    return dist_dataset\n",
    "    \n",
    "    \n",
    "train_dist_dataset = create_dist_dataset(X_train_mlm, y_train_mlm, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b6b765",
   "metadata": {
    "_cell_guid": "3ba0b8c0-3e4c-4afe-8766-844c6b6a8c0f",
    "_uuid": "9f6161c2-a256-4285-9a0e-f23700f4b195",
    "execution": {
     "iopub.execute_input": "2024-09-10T18:38:02.408778Z",
     "iopub.status.busy": "2024-09-10T18:38:02.408490Z",
     "iopub.status.idle": "2024-09-10T18:39:20.254462Z",
     "shell.execute_reply": "2024-09-10T18:39:20.253757Z"
    },
    "papermill": {
     "duration": 77.856127,
     "end_time": "2024-09-10T18:39:20.256319",
     "exception": false,
     "start_time": "2024-09-10T18:38:02.400192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/models/auto/modeling_tf_auto.py:721: FutureWarning: The class `TFAutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `TFAutoModelForCausalLM` for causal language models, `TFAutoModelForMaskedLM` for masked language models and `TFAutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/config.json HTTP/11\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/model.safetensors HTTP/11\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /jplu/tf-xlm-roberta-large/resolve/main/tf_model.h5 HTTP/11\" 302 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to acquire lock 134144582578336 on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/bd502c50deb6efcb00fd91768ac2a933716d50b8d85b1fcad21b7d3116ed25c7.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Lock 134144582578336 acquired on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/bd502c50deb6efcb00fd91768ac2a933716d50b8d85b1fcad21b7d3116ed25c7.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn-lfs.huggingface.co:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://cdn-lfs.huggingface.co:443 \"GET /jplu/tf-xlm-roberta-large/bd502c50deb6efcb00fd91768ac2a933716d50b8d85b1fcad21b7d3116ed25c7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tf_model.h5%3B+filename%3D%22tf_model.h5%22%3B&Expires=1726252684&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNjI1MjY4NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9qcGx1L3RmLXhsbS1yb2JlcnRhLWxhcmdlL2JkNTAyYzUwZGViNmVmY2IwMGZkOTE3NjhhYzJhOTMzNzE2ZDUwYjhkODViMWZjYWQyMWI3ZDMxMTZlZDI1Yzc~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=HYfoKlUMTP2gFEtnEUnjqW45I4MTL6pzYrakcwmas61EwcaRXRekm7DEGyW28AShtgdexyIxyCoI9Y-cMDIzLzHInvXCuaVyiOxbgjVOfyBylmNIIPIbon8VEHDa1kRpFTYsXqyLoa9yAc4fiNF4EmAzRbCfhEHRzMojmr5cx6XDmVq0qusz-Wy~WUfwtmkEYc3CTnfb3-R0yzwOiOZyUo7x-XN9DZFteInfp4TuYxUnQrqp2CHn7G8R~s8NoZ5AZDGEA8e9eIS3bCKy8NJEWnDpk50-tvvaMWRxeABu4TTDCdCodJMo-wZhZ-3lpowo-EDlf4exf92CMvEZPK3e8g__&Key-Pair-Id=K3ESJI6DHPFC7 HTTP/11\" 200 3271420488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 134144582578336 on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/bd502c50deb6efcb00fd91768ac2a933716d50b8d85b1fcad21b7d3116ed25c7.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Lock 134144582578336 released on /root/.cache/huggingface/hub/.locks/models--jplu--tf-xlm-roberta-large/bd502c50deb6efcb00fd91768ac2a933716d50b8d85b1fcad21b7d3116ed25c7.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725993495.280296      77 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaForMaskedLM.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the layers of TFXLMRobertaForMaskedLM were initialized from the model checkpoint at jplu/tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfxlm_roberta_for_masked_lm\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " roberta (TFXLMRobertaMainL  multiple                  558840832 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ayer)                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lm_head (TFXLMRobertaLMHea  multiple                  257833106 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " d)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 560142482 (2.09 GB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 560142482 (2.09 GB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0 (0.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.6 s, sys: 1min 18s, total: 2min 9s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def create_mlm_model_and_optimizer():\n",
    "    with strategy.scope():\n",
    "        model = TFAutoModelWithLMHead.from_pretrained(PRETRAINED_MODEL)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "    return model, optimizer\n",
    "\n",
    "\n",
    "mlm_model, optimizer = create_mlm_model_and_optimizer()\n",
    "mlm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cdf06b0",
   "metadata": {
    "_cell_guid": "20b20e6a-16c4-475f-92ef-2a7809d21621",
    "_uuid": "50c766ac-68bd-4884-ba54-657f5d385786",
    "execution": {
     "iopub.execute_input": "2024-09-10T18:39:20.292196Z",
     "iopub.status.busy": "2024-09-10T18:39:20.291897Z",
     "iopub.status.idle": "2024-09-10T18:39:20.379015Z",
     "shell.execute_reply": "2024-09-10T18:39:20.378175Z"
    },
    "papermill": {
     "duration": 0.098565,
     "end_time": "2024-09-10T18:39:20.381016",
     "exception": false,
     "start_time": "2024-09-10T18:39:20.282451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_mlm_loss_and_metrics():\n",
    "    with strategy.scope():\n",
    "        mlm_loss_object = masked_sparse_categorical_crossentropy\n",
    "\n",
    "        def compute_mlm_loss(labels, predictions):\n",
    "            per_example_loss = mlm_loss_object(labels, predictions)\n",
    "            loss = tf.nn.compute_average_loss(\n",
    "                per_example_loss, global_batch_size = global_batch_size)\n",
    "            return loss\n",
    "\n",
    "        train_mlm_loss_metric = tf.keras.metrics.Mean()\n",
    "        \n",
    "    return compute_mlm_loss, train_mlm_loss_metric\n",
    "\n",
    "\n",
    "def masked_sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "    y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true_masked,\n",
    "                                                          y_pred_masked,\n",
    "                                                          from_logits=True)\n",
    "    return loss\n",
    "\n",
    "            \n",
    "            \n",
    "def train_mlm(train_dist_dataset, total_steps=2000, evaluate_every=200):\n",
    "    step = 0\n",
    "    ### Training lopp ###\n",
    "    for tensor in train_dist_dataset:\n",
    "        distributed_mlm_train_step(tensor) \n",
    "        step+=1\n",
    "\n",
    "        if (step % evaluate_every == 0):   \n",
    "            ### Print train metrics ###  \n",
    "            train_metric = train_mlm_loss_metric.result().numpy()\n",
    "            print(\"Step %d, train loss: %.2f\" % (step, train_metric))     \n",
    "\n",
    "            ### Reset  metrics ###\n",
    "            train_mlm_loss_metric.reset_state()\n",
    "            \n",
    "        if step  == total_steps:\n",
    "            break\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def distributed_mlm_train_step(data):\n",
    "    strategy.run(mlm_train_step, args=(data,))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def mlm_train_step(inputs):\n",
    "    features, labels = inputs\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = mlm_model(features, training=True)[0]\n",
    "        loss = compute_mlm_loss(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, mlm_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, mlm_model.trainable_variables))\n",
    "\n",
    "    train_mlm_loss_metric.update_state(loss)\n",
    "    \n",
    "\n",
    "compute_mlm_loss, train_mlm_loss_metric = define_mlm_loss_and_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a41513d9",
   "metadata": {
    "_cell_guid": "d3d0e97f-d7d4-4d3f-8c6e-925669565248",
    "_uuid": "b30a95a7-ae7e-40e8-846b-9d31bfe997ad",
    "execution": {
     "iopub.execute_input": "2024-09-10T18:39:20.419966Z",
     "iopub.status.busy": "2024-09-10T18:39:20.419693Z",
     "iopub.status.idle": "2024-09-10T18:57:20.860930Z",
     "shell.execute_reply": "2024-09-10T18:57:20.860131Z"
    },
    "papermill": {
     "duration": 1080.461594,
     "end_time": "2024-09-10T18:57:20.870740",
     "exception": false,
     "start_time": "2024-09-10T18:39:20.409146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:absl:`TPUStrategy.run` is called with [args: ((PerReplica:{\n",
      "  0: <tf.Tensor 'data:0' shape=(8, 128) dtype=int64>,\n",
      "  1: <tf.Tensor 'data_1:0' shape=(8, 128) dtype=int64>,\n",
      "  2: <tf.Tensor 'data_2:0' shape=(8, 128) dtype=int64>,\n",
      "  3: <tf.Tensor 'data_3:0' shape=(8, 128) dtype=int64>,\n",
      "  4: <tf.Tensor 'data_4:0' shape=(8, 128) dtype=int64>,\n",
      "  5: <tf.Tensor 'data_5:0' shape=(8, 128) dtype=int64>,\n",
      "  6: <tf.Tensor 'data_6:0' shape=(8, 128) dtype=int64>,\n",
      "  7: <tf.Tensor 'data_7:0' shape=(8, 128) dtype=int64>\n",
      "}, PerReplica:{\n",
      "  0: <tf.Tensor 'data_8:0' shape=(8, 128) dtype=int64>,\n",
      "  1: <tf.Tensor 'data_9:0' shape=(8, 128) dtype=int64>,\n",
      "  2: <tf.Tensor 'data_10:0' shape=(8, 128) dtype=int64>,\n",
      "  3: <tf.Tensor 'data_11:0' shape=(8, 128) dtype=int64>,\n",
      "  4: <tf.Tensor 'data_12:0' shape=(8, 128) dtype=int64>,\n",
      "  5: <tf.Tensor 'data_13:0' shape=(8, 128) dtype=int64>,\n",
      "  6: <tf.Tensor 'data_14:0' shape=(8, 128) dtype=int64>,\n",
      "  7: <tf.Tensor 'data_15:0' shape=(8, 128) dtype=int64>\n",
      "}),)] [kwargs: None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 256002048 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:42:15.495483: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725993738.746941     871 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(31ce53bfedaec854:0:0), session_name()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725993787.191303     871 tpu_compile_op_common.cc:245] Compilation of 31ce53bfedaec854:0:0 with session name  took 48.444303416s and succeeded\n",
      "I0000 00:00:1725993787.328330     871 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(31ce53bfedaec854:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_distributed_mlm_train_step_14513142017370184479\", property.function_library_fingerprint = 10213811425343110180, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\n",
      "I0000 00:00:1725993787.328413     871 tpu_compilation_cache_interface.cc:541] After adding entry for key 31ce53bfedaec854:0:0 with session_name  cache is 1 entries (390209762 bytes),  marked for eviction 0 entries (0 bytes).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200, train loss: 2.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400, train loss: 1.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600, train loss: 1.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800, train loss: 1.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000, train loss: 1.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1200, train loss: 1.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1400, train loss: 1.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1600, train loss: 1.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1800, train loss: 1.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000, train loss: 1.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 48s, sys: 2min 16s, total: 22min 5s\n",
      "Wall time: 18min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_mlm(train_dist_dataset, TOTAL_STEPS, EVALUATE_EVERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5967d61",
   "metadata": {
    "_cell_guid": "96a7be93-0dce-4d00-92c4-d4c4cb2238f8",
    "_uuid": "5cd548e4-5756-4d92-b72c-f71cb72b395d",
    "execution": {
     "iopub.execute_input": "2024-09-10T18:57:20.914974Z",
     "iopub.status.busy": "2024-09-10T18:57:20.914023Z",
     "iopub.status.idle": "2024-09-10T18:57:30.109184Z",
     "shell.execute_reply": "2024-09-10T18:57:30.108088Z"
    },
    "papermill": {
     "duration": 9.210259,
     "end_time": "2024-09-10T18:57:30.112212",
     "exception": false,
     "start_time": "2024-09-10T18:57:20.901953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:h5py._conv:Creating converter from 5 to 3\n"
     ]
    }
   ],
   "source": [
    "mlm_model.save_pretrained('./')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 2703900,
     "sourceId": 19018,
     "sourceType": "competition"
    },
    {
     "datasetId": 588377,
     "sourceId": 1062669,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1276.547492,
   "end_time": "2024-09-10T18:57:37.126528",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-10T18:36:20.579036",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
